# ğŸš€ Cluster Apache Spark sur Google Cloud Platform - Automatisation complÃ¨te

> DÃ©ploiement automatisÃ© d'un cluster Apache Spark distribuÃ© sur GCP avec HDFS, utilisant Terraform et Ansible.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Terraform](https://img.shields.io/badge/Terraform-1.0+-purple.svg)](https://www.terraform.io/)
[![Ansible](https://img.shields.io/badge/Ansible-2.9+-red.svg)](https://www.ansible.com/)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-orange.svg)](https://spark.apache.org/)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.6-yellow.svg)](https://hadoop.apache.org/)

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#-vue-densemble)
2. [Architecture](#-architecture)
3. [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
4. [PrÃ©requis](#-prÃ©requis)
5. [Installation pas Ã  pas](#-installation-pas-Ã -pas)
6. [Utilisation](#-utilisation)
7. [Application WordCount](#-application-wordcount)
8. [Benchmarking](#-benchmarking)
9. [Maintenance et opÃ©rations](#-maintenance-et-opÃ©rations)
10. [DÃ©pannage](#-dÃ©pannage)
11. [Architecture avancÃ©e](#-architecture-avancÃ©e)
12. [Contribuer](#-contribuer)
13. [Licence](#-licence)

---

## ğŸ¯ Vue d'ensemble

Ce projet fournit une solution **clÃ© en main** pour dÃ©ployer un cluster Apache Spark de production sur Google Cloud Platform (GCP). Il combine l'Infrastructure as Code (IaC) avec Terraform et la gestion de configuration avec Ansible pour automatiser complÃ¨tement le provisionnement et la configuration.

### Objectifs du projet

- âœ… **Automatisation complÃ¨te** : DÃ©ploiement en une seule commande
- âœ… **ReproductibilitÃ©** : Infrastructure versionnable et reproductible
- âœ… **Production-ready** : Configuration optimisÃ©e pour la production
- âœ… **Ã‰volutivitÃ©** : Ajout facile de nouveaux workers
- âœ… **ObservabilitÃ©** : Interfaces Web pour monitoring
- âœ… **Stockage distribuÃ©** : HDFS intÃ©grÃ© pour la persistance des donnÃ©es

### Cas d'usage

- **Big Data Analytics** : Traitement de volumes massifs de donnÃ©es
- **Machine Learning** : EntraÃ®nement de modÃ¨les distribuÃ©s avec MLlib
- **ETL** : Extract, Transform, Load de donnÃ©es Ã  grande Ã©chelle
- **Stream Processing** : Traitement de donnÃ©es en temps rÃ©el
- **Data Science** : Analyse exploratoire sur donnÃ©es volumineuses

---

## ğŸ—ï¸ Architecture

### Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google Cloud Platform (GCP)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      VPC Network (10.0.0.0/16)              â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚   Master     â”‚  â”‚   Worker 1   â”‚  â”‚   Worker 2   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚  10.0.0.5    â”‚  â”‚  10.0.0.2    â”‚  â”‚  10.0.0.4    â”‚     â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ Spark Master â”‚  â”‚ Spark Worker â”‚  â”‚ Spark Worker â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ HDFS NameNodeâ”‚  â”‚ HDFS DataNodeâ”‚  â”‚ HDFS DataNodeâ”‚     â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ e2-standard-4â”‚  â”‚ e2-standard-2â”‚  â”‚ e2-standard-2â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ 4 vCPUs/16GB â”‚  â”‚ 2 vCPUs/8GB  â”‚  â”‚ 2 vCPUs/8GB  â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚ â”‚
â”‚  â”‚  â”‚  Edge Node   â”‚  (Point d'entrÃ©e pour les jobs)          â”‚ â”‚
â”‚  â”‚  â”‚  10.0.0.3    â”‚                                           â”‚ â”‚
â”‚  â”‚  â”‚              â”‚                                           â”‚ â”‚
â”‚  â”‚  â”‚ Spark Client â”‚                                           â”‚ â”‚
â”‚  â”‚  â”‚ e2-medium    â”‚                                           â”‚ â”‚
â”‚  â”‚  â”‚ 2 vCPUs/4GB  â”‚                                           â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â”‚  AccÃ¨s externe via IPs publiques + Firewall Rules               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants du cluster

#### 1. **Spark Master** (NÅ“ud principal)
- **RÃ´le** : Orchestration du cluster Spark
- **Services** :
  - Spark Master (port 7077)
  - Spark Web UI (port 8080)
  - HDFS NameNode (port 9000, 9870)
- **Machine** : e2-standard-4 (4 vCPUs, 16 GB RAM)
- **Stockage** : 50 GB SSD

#### 2. **Spark Workers** (NÅ“uds de calcul) Ã— 2
- **RÃ´le** : ExÃ©cution des tÃ¢ches Spark
- **Services** :
  - Spark Worker (port 8081)
  - HDFS DataNode (port 9866, 9864)
- **Machine** : e2-standard-2 (2 vCPUs, 8 GB RAM)
- **Stockage** : 50 GB SSD

#### 3. **Edge Node** (NÅ“ud client)
- **RÃ´le** : Point d'entrÃ©e pour soumettre des jobs
- **Services** :
  - Spark Client
  - HDFS Client
- **Machine** : e2-medium (2 vCPUs, 4 GB RAM)
- **Stockage** : 30 GB SSD

### Architecture rÃ©seau

```
Internet
    â”‚
    â”œâ”€â”€â”€ Firewall Rules
    â”‚    â”œâ”€ SSH (22) : AccÃ¨s admin
    â”‚    â”œâ”€ Spark Master UI (8080) : Monitoring
    â”‚    â”œâ”€ Spark Worker UI (8081) : Monitoring
    â”‚    â””â”€ HDFS NameNode UI (9870) : Monitoring
    â”‚
    â””â”€â”€â”€ VPC 10.0.0.0/16
         â”‚
         â”œâ”€ Subnet: spark-subnet (10.0.0.0/24)
         â”‚  â””â”€ Communication interne entre nÅ“uds
         â”‚
         â””â”€ NAT Gateway (pour accÃ¨s sortant)
```

### Architecture Spark

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spark Application                    â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚   Driver     â”‚  (Gestion du job, DAG, scheduling)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                                â”‚
â”‚         â”‚ spark://master:7077                           â”‚
â”‚         â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚         Spark Cluster Manager             â”‚         â”‚
â”‚  â”‚           (Standalone Mode)                â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                          â”‚
â”‚    â”‚         â”‚                                          â”‚
â”‚  â”Œâ”€â–¼â”€â”€â”   â”Œâ”€â–¼â”€â”€â”                                       â”‚
â”‚  â”‚ Ex â”‚   â”‚ Ex â”‚  (Executors - ExÃ©cution des tasks)   â”‚
â”‚  â”‚ W1 â”‚   â”‚ W2 â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture HDFS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HDFS Architecture                      â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚    NameNode       â”‚  (MÃ©tadonnÃ©es, namespace)         â”‚
â”‚  â”‚   Master Node     â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚            â”‚                                               â”‚
â”‚            â”‚ Heartbeat & Block Reports                    â”‚
â”‚            â”‚                                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚    â”‚              â”‚                                       â”‚
â”‚  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”                                â”‚
â”‚  â”‚DataNodeâ”‚   â”‚DataNodeâ”‚  (Stockage des blocs de donnÃ©es)â”‚
â”‚  â”‚Worker 1â”‚   â”‚Worker 2â”‚                                 â”‚
â”‚  â”‚        â”‚   â”‚        â”‚                                 â”‚
â”‚  â”‚ Blocs: â”‚   â”‚ Blocs: â”‚                                 â”‚
â”‚  â”‚ [B1,B3]â”‚   â”‚ [B2,B4]â”‚  (RÃ©plication: 2)               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                                            â”‚
â”‚  DonnÃ©es distribuÃ©es et rÃ©pliquÃ©es pour haute disponibilitÃ©â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es

```
1. Soumission du job
   User â†’ Edge Node â†’ spark-submit â†’ Spark Master

2. Allocation des ressources
   Spark Master â†’ Workers (crÃ©ation des Executors)

3. Lecture des donnÃ©es
   Executors â†’ HDFS DataNodes (lecture parallÃ¨le des blocs)

4. Traitement
   Executors â†’ Transformations/Actions sur les RDDs/DataFrames

5. Ã‰criture des rÃ©sultats
   Executors â†’ HDFS DataNodes (Ã©criture parallÃ¨le)

6. Retour au client
   Spark Master â†’ Edge Node (rÃ©sultats agrÃ©gÃ©s)
```

---

## ğŸ”§ Technologies utilisÃ©es

### Infrastructure

| Technologie | Version | RÃ´le |
|------------|---------|------|
| **Terraform** | 1.0+ | Infrastructure as Code (provisionnement GCP) |
| **Ansible** | 2.9+ | Configuration management (installation et config) |
| **Google Cloud Platform** | - | Cloud provider (compute, network, storage) |

### Big Data Stack

| Technologie | Version | RÃ´le |
|------------|---------|------|
| **Apache Spark** | 3.5.0 | Framework de traitement distribuÃ© |
| **Apache Hadoop** | 3.3.6 | SystÃ¨me de fichiers distribuÃ© (HDFS) |
| **Scala** | 2.12.18 | Langage pour applications Spark |
| **SBT** | 1.9+ | Build tool pour Scala |

### SystÃ¨me

| Technologie | Version | RÃ´le |
|------------|---------|------|
| **Ubuntu** | 22.04 LTS | SystÃ¨me d'exploitation |
| **OpenJDK** | 11 | Runtime Java pour Spark/Hadoop |
| **systemd** | - | Gestion des services |

---

## ğŸ“¦ PrÃ©requis

### Sur votre machine locale

#### 1. Terraform (â‰¥ 1.0)

**Installation sur Linux/macOS :**
```bash
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/
terraform --version
```

**Installation sur Windows :**
```powershell
choco install terraform
```

#### 2. Ansible (â‰¥ 2.9)

**Installation sur Linux :**
```bash
sudo apt update
sudo apt install -y ansible
ansible --version
```

**Installation sur macOS :**
```bash
brew install ansible
```

#### 3. Google Cloud SDK

**Installation :**
```bash
curl https://sdk.cloud.google.com | bash
exec -l $SHELL
gcloud init
```

**VÃ©rification :**
```bash
gcloud --version
```

#### 4. Autres outils

```bash
# Git
sudo apt install -y git

# SSH
sudo apt install -y openssh-client

# Python 3
sudo apt install -y python3 python3-pip

# jq (pour parsing JSON)
sudo apt install -y jq
```

### Compte Google Cloud Platform

#### 1. CrÃ©er un projet GCP

1. Aller sur [Google Cloud Console](https://console.cloud.google.com/)
2. CrÃ©er un nouveau projet (ex: `spark-automation`)
3. Noter le Project ID (ex: `spark-automation-1767083359`)

#### 2. Activer les APIs nÃ©cessaires

```bash
gcloud services enable compute.googleapis.com
gcloud services enable servicenetworking.googleapis.com
```

#### 3. CrÃ©er un Service Account

```bash
# CrÃ©er le service account
gcloud iam service-accounts create terraform-sa \
    --display-name="Terraform Service Account"

# Donner les permissions nÃ©cessaires
gcloud projects add-iam-policy-binding YOUR_PROJECT_ID \
    --member="serviceAccount:terraform-sa@YOUR_PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/editor"

# GÃ©nÃ©rer la clÃ© JSON
gcloud iam service-accounts keys create ~/gcp-key.json \
    --iam-account=terraform-sa@YOUR_PROJECT_ID.iam.gserviceaccount.com
```

**âš ï¸ Important** : Sauvegarder le fichier `~/gcp-key.json` de maniÃ¨re sÃ©curisÃ©e !

#### 4. Configurer les quotas GCP

VÃ©rifier que vous avez les quotas suffisants :
- **CPUs** : Au moins 12 vCPUs (4+2+2+2+2)
- **IPs externes** : Au moins 4
- **Disques persistants** : Au moins 220 GB

---

## ğŸš€ Installation pas Ã  pas

### Ã‰tape 1 : Cloner le projet

```bash
git clone <votre-repo>
cd spark-gcp-automation
```

### Ã‰tape 2 : Configuration initiale

#### 2.1 Configurer Terraform

```bash
cd terraform/environments/dev
```

CrÃ©er le fichier `terraform.tfvars` :

```hcl
# terraform.tfvars
project_id = "votre-project-id-gcp"
region     = "us-central1"
zone       = "us-central1-a"

# Optionnel : personnaliser les machines
master_machine_type = "e2-standard-4"
worker_machine_type = "e2-standard-2"
worker_count        = 2
```

#### 2.2 Initialiser Terraform

```bash
terraform init
```

**Sortie attendue :**
```
Initializing the backend...
Initializing provider plugins...
Terraform has been successfully initialized!
```

#### 2.3 GÃ©nÃ©rer la clÃ© SSH

```bash
ssh-keygen -t rsa -b 4096 -f ~/.ssh/spark-cluster -N "" -C "spark-admin"
```

### Ã‰tape 3 : DÃ©ploiement de l'infrastructure

#### 3.1 Planifier le dÃ©ploiement

```bash
terraform plan
```

**VÃ©rifier** :
- âœ… Nombre de ressources Ã  crÃ©er
- âœ… Types de machines
- âœ… Configuration rÃ©seau

#### 3.2 Appliquer le dÃ©ploiement

```bash
terraform apply
```

Taper `yes` pour confirmer.

**DurÃ©e estimÃ©e** : 3-5 minutes

**Sortie attendue :**
```
Apply complete! Resources: 15 added, 0 changed, 0 destroyed.

Outputs:

master_ip = "35.239.9.113"
worker_ips = [
  "136.115.114.65",
  "34.123.84.20",
]
edge_public_ip = "34.59.1.236"
spark_ui_url = "http://35.239.9.113:8080"
```

**ğŸ“ Noter** : Conserver les IPs affichÃ©es !

#### 3.3 VÃ©rifier l'infrastructure

```bash
# Lister les VMs crÃ©Ã©es
gcloud compute instances list

# Tester la connectivitÃ© SSH
ssh -i ~/.ssh/spark-cluster spark-admin@<MASTER_IP>
exit
```

### Ã‰tape 4 : Configuration avec Ansible

#### 4.1 PrÃ©parer l'inventaire

```bash
cd ../../../ansible
```

VÃ©rifier que l'inventaire a Ã©tÃ© gÃ©nÃ©rÃ© automatiquement :

```bash
cat inventory/hosts.ini
```

**Contenu attendu :**
```ini
[spark_master]
35.239.9.113 ansible_user=spark-admin ansible_ssh_private_key_file=~/.ssh/spark-cluster

[spark_workers]
136.115.114.65 ansible_user=spark-admin ansible_ssh_private_key_file=~/.ssh/spark-cluster
34.123.84.20 ansible_user=spark-admin ansible_ssh_private_key_file=~/.ssh/spark-cluster

[spark_edge]
34.59.1.236 ansible_user=spark-admin ansible_ssh_private_key_file=~/.ssh/spark-cluster

[spark_cluster:children]
spark_master
spark_workers
spark_edge
```

#### 4.2 Tester la connectivitÃ© Ansible

```bash
ansible all -m ping
```

**Sortie attendue :**
```
35.239.9.113 | SUCCESS => {"changed": false, "ping": "pong"}
136.115.114.65 | SUCCESS => {"changed": false, "ping": "pong"}
34.123.84.20 | SUCCESS => {"changed": false, "ping": "pong"}
34.59.1.236 | SUCCESS => {"changed": false, "ping": "pong"}
```

**âš ï¸ Si Ã©chec** : Attendre 1-2 minutes que les VMs finissent leur initialisation.

#### 4.3 DÃ©ployer Spark

```bash
ansible-playbook playbooks/deploy-spark.yml -v
```

**DurÃ©e estimÃ©e** : 10-15 minutes

**Ce qui est installÃ©** :
1. âœ… Java OpenJDK 11
2. âœ… Apache Spark 3.5.0
3. âœ… Configuration des utilisateurs et groupes
4. âœ… Services systemd (spark-master, spark-worker)
5. âœ… Configuration rÃ©seau interne
6. âœ… DÃ©marrage automatique des services

**Sortie attendue (fin) :**
```
PLAY RECAP *******************************************
35.239.9.113    : ok=25   changed=15   unreachable=0   failed=0
136.115.114.65  : ok=22   changed=14   unreachable=0   failed=0
34.123.84.20    : ok=22   changed=14   unreachable=0   failed=0
34.59.1.236     : ok=18   changed=12   unreachable=0   failed=0

Cluster Spark dÃ©ployÃ© !
Master UI: http://35.239.9.113:8080
```

#### 4.4 VÃ©rifier Spark

**Ouvrir dans le navigateur** : `http://<MASTER_IP>:8080`

**VÃ©rifier** :
- âœ… Workers : 2 actifs
- âœ… Cores : 4 total (2 par worker)
- âœ… Memory : 8 GB total (4 GB par worker)

### Ã‰tape 5 : DÃ©ployer HDFS

#### 5.1 Lancer le dÃ©ploiement HDFS

```bash
ansible-playbook playbooks/deploy-hdfs.yml -v
```

**DurÃ©e estimÃ©e** : 15-20 minutes

**Ce qui est installÃ©** :
1. âœ… Hadoop 3.3.6
2. âœ… Configuration HDFS (NameNode + DataNodes)
3. âœ… Formatage du NameNode
4. âœ… Configuration SSH entre nÅ“uds
5. âœ… Services systemd (hdfs-namenode, hdfs-datanode)
6. âœ… CrÃ©ation des rÃ©pertoires utilisateurs dans HDFS

**Sortie attendue (fin) :**
```
TASK [Message de succÃ¨s] *************************************
ok: [35.239.9.113] =>
  msg:
  - =====================================
  - HDFS dÃ©ployÃ© avec succÃ¨s !
  - =====================================
  - NameNode UI: http://10.0.0.5:9870
  - HDFS URI: hdfs://10.0.0.5:9000
  - =====================================

PLAY RECAP *************************************************
35.239.9.113    : ok=9    changed=4    unreachable=0    failed=0
136.115.114.65  : ok=3    changed=1    unreachable=0    failed=0
34.123.84.20    : ok=3    changed=1    unreachable=0    failed=0
```

#### 5.2 VÃ©rifier HDFS

**SSH vers le master :**
```bash
ssh -i ~/.ssh/spark-cluster spark-admin@<MASTER_IP>
sudo su - hadoop
source /etc/profile.d/hadoop.sh

# VÃ©rifier le rapport HDFS
hdfs dfsadmin -report
```

**Sortie attendue :**
```
Configured Capacity: 103670202368 (96.55 GB)
Present Capacity: 90261950464 (84.06 GB)
DFS Remaining: 90261901312 (84.06 GB)
DFS Used: 49152 (48 KB)
DFS Used%: 0.00%
...
Live datanodes (2):
...
```

**VÃ©rifier l'UI** : `http://<MASTER_IP>:9870`

âœ… Vous devriez voir :
- 2 DataNodes actifs
- ~96 GB de capacitÃ©
- 0% utilisÃ©

### Ã‰tape 6 : DÃ©ployer l'application WordCount

#### 6.1 Compiler le projet

```bash
cd ../wordcount
./build.sh
```

**Sortie attendue :**
```
==========================================
Compilation WordCount
==========================================
[info] Compilation en cours...
[success] Total time: 12 s
âœ“ Compilation rÃ©ussie
JAR: target/scala-2.12/wordcount.jar
-rw-rw-r-- 1 user user 5.3M wordcount.jar
```

#### 6.2 DÃ©ployer sur le cluster

```bash
./deploy-to-cluster.sh
```

**Ce script va** :
1. RÃ©cupÃ©rer l'IP du nÅ“ud Edge depuis Terraform
2. CrÃ©er le rÃ©pertoire sur l'Edge
3. Copier le JAR compilÃ©
4. Copier les donnÃ©es de test

**Sortie attendue :**
```
==========================================
DÃ©ploiement WordCount sur le cluster
==========================================
Edge IP: 34.59.1.236
Master IP: 35.239.9.113
âœ“ DÃ©ploiement terminÃ©

Pour exÃ©cuter:
  ssh -i ~/.ssh/spark-cluster spark-admin@34.59.1.236
  cd /home/spark-admin/wordcount
  /opt/spark/bin/spark-submit \
    --class WordCount \
    --master spark://35.239.9.113:7077 \
    --num-executors 2 \
    --executor-memory 2G \
    wordcount.jar sample.txt output
```

#### 6.3 Uploader les donnÃ©es dans HDFS

```bash
./upload-to-hdfs.sh
```

**Ce script va** :
1. Copier les fichiers vers le master
2. CrÃ©er les rÃ©pertoires dans HDFS
3. Uploader `sample.txt` et `benchmark_input.txt`

**Sortie attendue :**
```
==========================================
Upload des donnÃ©es vers HDFS
==========================================
Master IP: 35.239.9.113

Fichiers dans HDFS:
-rw-r--r--   2 hadoop supergroup      12M benchmark_input.txt
-rw-r--r--   2 hadoop supergroup    1.3K sample.txt

âœ“ DonnÃ©es uploadÃ©es vers HDFS
```

### Ã‰tape 7 : Tester l'installation

#### 7.1 Test simple sur HDFS

```bash
ssh -i ~/.ssh/spark-cluster spark-admin@<EDGE_IP>
cd /home/spark-admin/wordcount

# Lancer un job simple
/opt/spark/bin/spark-submit \
  --class WordCount \
  --master spark://10.0.0.5:7077 \
  --num-executors 2 \
  --executor-memory 1G \
  --executor-cores 1 \
  wordcount.jar \
  hdfs://10.0.0.5:9000/user/spark-admin/wordcount/input/sample.txt \
  hdfs://10.0.0.5:9000/user/spark-admin/wordcount/output/test-$(date +%s)
```

**Sortie attendue :**
```
=== WordCount Starting ===
Input: hdfs://10.0.0.5:9000/user/spark-admin/wordcount/input/sample.txt
Output: hdfs://10.0.0.5:9000/user/spark-admin/wordcount/output/test-1767344567
Executors: 2
Total lines: 20
Unique words: 15

=== Top 20 Most Frequent Words ===
spark                :      5
cluster              :      3
data                 :      2
...

=== WordCount Completed ===
Execution time: 8.45 seconds
```

#### 7.2 VÃ©rifier les rÃ©sultats dans HDFS

```bash
# Lister les rÃ©sultats
hdfs dfs -ls hdfs://10.0.0.5:9000/user/spark-admin/wordcount/output/

# Lire les rÃ©sultats
hdfs dfs -cat hdfs://10.0.0.5:9000/user/spark-admin/wordcount/output/test-*/part-* | head -20
```

---

## ğŸ’» Utilisation

### Soumettre un job Spark

#### Format gÃ©nÃ©ral

```bash
spark-submit \
  --class <MainClass> \
  --master <spark-master-url> \
  --deploy-mode <client|cluster> \
  --num-executors <nombre> \
  --executor-memory <RAM> \
  --executor-cores <cores> \
  --driver-memory <RAM> \
  <chemin-jar> \
  <arguments>
```

#### Exemple concret

```bash
/opt/spark/bin/spark-submit \
  --class WordCount \
  --master spark://10.0.0.5:7077 \
  --deploy-mode client \
  --num-executors 2 \
  --executor-memory 2G \
  --executor-cores 1 \
  --driver-memory 512M \
  wordcount.jar \
  hdfs://10.0.0.5:9000/user/spark-admin/input/data.txt \
  hdfs://10.0.0.5:9000/user/spark-admin/output/result
```

### Gestion HDFS

#### Commandes courantes

```bash
# Lister les fichiers
hdfs dfs -ls /user/spark-admin/

# CrÃ©er un rÃ©pertoire
hdfs dfs -mkdir -p /user/spark-admin/data

# Uploader un fichier
hdfs dfs -put local-file.txt /user/spark-admin/data/

# TÃ©lÃ©charger un fichier
hdfs dfs -get /user/spark-admin/data/file.txt ./

# Lire un fichier
hdfs dfs -cat /user/spark-admin/data/file.txt

# Supprimer un fichier
hdfs dfs -rm /user/spark-admin/data/file.txt

# Supprimer un rÃ©pertoire
hdfs dfs -rm -r /user/spark-admin/data/

# Voir l'espace disque
hdfs dfs -df -h

# Voir l'utilisation
hdfs dfs -du -h /user/spark-admin/
```

#### Gestion des permissions

```bash
# Changer le propriÃ©taire
hdfs dfs -chown user:group /path/to/file

# Changer les permissions
hdfs dfs -chmod 755 /path/to/file

# Changer rÃ©cursivement
hdfs dfs -chmod -R 755 /path/to/directory
```

### Monitoring

#### Interfaces Web

| Service | URL | Description |
|---------|-----|-------------|
| **Spark Master UI** | `http://<MASTER_IP>:8080` | Ã‰tat du cluster, workers, applications |
| **Spark Worker UI** | `http://<WORKER_IP>:8081` | DÃ©tails d'un worker spÃ©cifique |
| **HDFS NameNode UI** | `http://<MASTER_IP>:9870` | Ã‰tat HDFS, DataNodes, blocs |
| **Application UI** | `http://<DRIVER_IP>:4040` | DÃ©tails d'une application en cours |

#### Commandes de monitoring

```bash
# Ã‰tat du cluster Spark
curl http://<MASTER_IP>:8080/json/ | jq .

# Rapport HDFS
hdfs dfsadmin -report

# Ã‰tat des services
ssh spark-admin@<MASTER_IP> 'sudo systemctl status spark-master'
ssh spark-admin@<WORKER_IP> 'sudo systemctl status spark-worker'
ssh spark-admin@<MASTER_IP> 'sudo systemctl status hdfs-namenode'
ssh spark-admin@<WORKER_IP> 'sudo systemctl status hdfs-datanode'
```

---

## ğŸ“Š Application WordCount

### Description

WordCount est une application Spark qui :
1. Lit un fichier texte depuis HDFS
2. DÃ©coupe en mots
3. Compte les occurrences de chaque mot
4. Trie par frÃ©quence dÃ©croissante
5. Sauvegarde les rÃ©sultats dans HDFS

### Architecture de l'application

```scala
// Lecture
textFile = sc.textFile("hdfs://...")

// Transformation
words = textFile.flatMap(line => line.split("\\W+"))
wordCounts = words.map(word => (word, 1))
                  .reduceByKey(_ + _)
                  .sortBy(_._2, ascending = false)

// Action
wordCounts.saveAsTextFile("hdfs://...")
```

### Code source

Le code complet se trouve dans [wordcount/src/main/scala/WordCount.scala](wordcount/src/main/scala/WordCount.scala).

### Utilisation

```bash
# Se connecter Ã  l'Edge
ssh -i ~/.ssh/spark-cluster spark-admin@<EDGE_IP>
cd /home/spark-admin/wordcount

# ExÃ©cuter
/opt/spark/bin/spark-submit \
  --class WordCount \
  --master spark://10.0.0.5:7077 \
  --num-executors 2 \
  --executor-memory 1G \
  wordcount.jar \
  hdfs://10.0.0.5:9000/user/spark-admin/wordcount/input/sample.txt \
  hdfs://10.0.0.5:9000/user/spark-admin/wordcount/output/result-$(date +%s)
```

---

## ğŸ”¬ Benchmarking

### Script de benchmark

Le projet inclut un script de benchmark automatique qui teste diffÃ©rentes configurations :

```bash
cd /home/spark-admin/wordcount
./benchmark-hdfs.sh
```

### Configurations testÃ©es

| Config | Executors | RAM/Executor | Cores/Executor | Parallelism |
|--------|-----------|--------------|----------------|-------------|
| **Config 1** | 1 | 1G | 1 | 2 |
| **Config 2** | 2 | 1G | 1 | 4 |
| **Config 3** | 2 | 2G | 1 | 4 |

### MÃ©triques collectÃ©es

- â±ï¸ **DurÃ©e d'exÃ©cution** : Temps total du job
- ğŸ“Š **Top 10 mots** : Mots les plus frÃ©quents
- ğŸ’¾ **Taille de sortie** : Espace utilisÃ© dans HDFS
- ğŸ“ˆ **ParallÃ©lisme** : Nombre de tÃ¢ches parallÃ¨les

### Exemple de rÃ©sultats

```
==========================================
Benchmark WordCount HDFS - Fri Jan 02 09:30:00 UTC 2026
==========================================
HDFS: hdfs://10.0.0.5:9000
Spark Master: spark://10.0.0.5:7077
==========================================

--- Config: 1 executor(s), 1G RAM, 1 cores ---
DurÃ©e: 45s
Top 10 mots:
(the,15234)
(and,12456)
(spark,8901)
...

--- Config: 2 executor(s), 1G RAM, 1 cores ---
DurÃ©e: 28s
Top 10 mots:
(the,15234)
(and,12456)
(spark,8901)
...

--- Config: 2 executor(s), 2G RAM, 1 cores ---
DurÃ©e: 25s
Top 10 mots:
(the,15234)
(and,12456)
(spark,8901)
...

RÃ‰SUMÃ‰ DES PERFORMANCES:
DurÃ©e: 45s
DurÃ©e: 28s
DurÃ©e: 25s
```

### Analyse des performances

**Observations** :
- âœ… **ParallÃ©lisme amÃ©liore les performances** : 2 executors = ~38% plus rapide
- âœ… **RAM supplÃ©mentaire apporte un gain marginal** : 2G vs 1G = ~10% plus rapide
- âœ… **ScalabilitÃ© linÃ©aire** : Doubler les ressources â‰ˆ diviser le temps par 2

---

## ğŸ› ï¸ Maintenance et opÃ©rations

### RedÃ©marrer les services

#### Spark

```bash
# Master
ssh spark-admin@<MASTER_IP> 'sudo systemctl restart spark-master'

# Workers
ssh spark-admin@<WORKER_IP> 'sudo systemctl restart spark-worker'
```

#### HDFS

```bash
# NameNode
ssh spark-admin@<MASTER_IP> 'sudo systemctl restart hdfs-namenode'

# DataNodes
ssh spark-admin@<WORKER_IP> 'sudo systemctl restart hdfs-datanode'
```

### Ajouter un worker

#### 1. Modifier Terraform

```hcl
# terraform.tfvars
worker_count = 3  # Au lieu de 2
```

#### 2. Appliquer les changements

```bash
cd terraform/environments/dev
terraform apply
```

#### 3. Configurer le nouveau worker

```bash
cd ../../../ansible

# Mettre Ã  jour l'inventaire (le nouveau worker devrait apparaÃ®tre)
ansible-playbook playbooks/deploy-spark.yml --limit=<NEW_WORKER_IP>
ansible-playbook playbooks/deploy-hdfs.yml --limit=<NEW_WORKER_IP>
```

### Sauvegarder les donnÃ©es HDFS

```bash
# CrÃ©er un snapshot
ssh spark-admin@<MASTER_IP>
sudo su - hadoop
hdfs dfsadmin -safemode enter
hdfs dfsadmin -saveNamespace

# Sauvegarder les mÃ©tadonnÃ©es
tar -czf namenode-backup-$(date +%Y%m%d).tar.gz /data/hadoop/hdfs/namenode/

# Sortir du safe mode
hdfs dfsadmin -safemode leave
```

### Mise Ã  jour de Spark

#### 1. Modifier la version

```yaml
# ansible/roles/spark-master/defaults/main.yml
spark_version: "3.5.1"  # Nouvelle version
```

#### 2. RedÃ©ployer

```bash
ansible-playbook playbooks/deploy-spark.yml
```

### Logs

#### Localisation des logs

```
Spark Master:  /opt/spark/logs/
Spark Worker:  /opt/spark/logs/
HDFS NameNode: /var/log/hadoop/
HDFS DataNode: /var/log/hadoop/
```

#### Consulter les logs

```bash
# Logs Spark Master
ssh spark-admin@<MASTER_IP> 'tail -f /opt/spark/logs/spark-*-master*.out'

# Logs HDFS NameNode
ssh spark-admin@<MASTER_IP> 'tail -f /var/log/hadoop/hadoop-*-namenode*.log'

# Logs via systemd
ssh spark-admin@<MASTER_IP> 'sudo journalctl -u spark-master -f'
```

---

## ğŸ” DÃ©pannage

### ProblÃ¨me : Workers ne se connectent pas au Master

**SymptÃ´me** : 0 workers dans l'UI Spark (port 8080)

**Solution** :
```bash
# VÃ©rifier que le master Ã©coute
ssh spark-admin@<MASTER_IP> 'netstat -tlnp | grep 7077'

# VÃ©rifier les logs du worker
ssh spark-admin@<WORKER_IP> 'tail -50 /opt/spark/logs/spark-*-worker*.out'

# RedÃ©marrer le worker
ssh spark-admin@<WORKER_IP> 'sudo systemctl restart spark-worker'
```

### ProblÃ¨me : DataNodes ne se connectent pas au NameNode

**SymptÃ´me** : 0 DataNodes dans l'UI HDFS (port 9870)

**Solution** :
```bash
# VÃ©rifier que le NameNode Ã©coute
ssh spark-admin@<MASTER_IP> 'sudo netstat -tlnp | grep 9000'

# VÃ©rifier la configuration
ssh spark-admin@<WORKER_IP> 'cat /opt/hadoop/etc/hadoop/core-site.xml | grep fs.defaultFS'

# VÃ©rifier les logs
ssh spark-admin@<WORKER_IP> 'tail -100 /var/log/hadoop/hadoop-*-datanode*.log'

# RedÃ©marrer le DataNode
ssh spark-admin@<WORKER_IP> 'sudo systemctl restart hdfs-datanode'
```

### ProblÃ¨me : Job Spark Ã©choue avec "FileNotFoundException"

**SymptÃ´me** : `File hdfs://... does not exist`

**Solution** :
```bash
# VÃ©rifier que le fichier existe dans HDFS
ssh spark-admin@<MASTER_IP>
sudo su - hadoop
hdfs dfs -ls /user/spark-admin/wordcount/input/

# Si absent, uploader le fichier
hdfs dfs -put local-file.txt /user/spark-admin/wordcount/input/
```

### ProblÃ¨me : "Initial job has not accepted any resources"

**SymptÃ´me** : Job Spark ne dÃ©marre pas, attend indÃ©finiment

**Cause** : Pas assez de ressources disponibles

**Solution** :
```bash
# VÃ©rifier les ressources disponibles
# UI Spark : http://<MASTER_IP>:8080

# RÃ©duire les ressources demandÃ©es
spark-submit \
  --num-executors 1 \    # Au lieu de 2
  --executor-memory 1G \ # Au lieu de 2G
  --executor-cores 1 \   # Au lieu de 2
  ...
```

### ProblÃ¨me : HDFS en "Safe Mode"

**SymptÃ´me** : `Name node is in safe mode`

**Solution** :
```bash
ssh spark-admin@<MASTER_IP>
sudo su - hadoop

# VÃ©rifier le statut
hdfs dfsadmin -safemode get

# Forcer la sortie (si sÃ»r)
hdfs dfsadmin -safemode leave
```

### ProblÃ¨me : Terraform apply Ã©choue

**SymptÃ´me** : `Error creating instance: quota exceeded`

**Solution** :
```bash
# VÃ©rifier les quotas
gcloud compute project-info describe --project=YOUR_PROJECT_ID

# Demander une augmentation de quota via GCP Console
# Ou rÃ©duire les ressources demandÃ©es dans terraform.tfvars
```

### ProblÃ¨me : Ansible ping Ã©choue

**SymptÃ´me** : `UNREACHABLE! => {"changed": false, "msg": "Failed to connect"}`

**Solution** :
```bash
# VÃ©rifier que les VMs sont dÃ©marrÃ©es
gcloud compute instances list

# VÃ©rifier la clÃ© SSH
ls -la ~/.ssh/spark-cluster*

# Tester SSH manuellement
ssh -i ~/.ssh/spark-cluster spark-admin@<MASTER_IP>

# VÃ©rifier les rÃ¨gles firewall
gcloud compute firewall-rules list
```

---

## ğŸ›ï¸ Architecture avancÃ©e

### Optimisations possibles

#### 1. Ajouter un Load Balancer

```hcl
# terraform/modules/network/main.tf
resource "google_compute_forwarding_rule" "spark_lb" {
  name       = "spark-lb"
  target     = google_compute_target_pool.spark_pool.self_link
  port_range = "7077"
}

resource "google_compute_target_pool" "spark_pool" {
  name = "spark-pool"
  instances = [
    for instance in google_compute_instance.spark_workers : instance.self_link
  ]
}
```

#### 2. Utiliser Preemptible VMs (coÃ»t rÃ©duit)

```hcl
# terraform/modules/compute/main.tf
resource "google_compute_instance" "spark_workers" {
  ...
  scheduling {
    preemptible       = true
    automatic_restart = false
  }
}
```

#### 3. Ajouter un autoscaler

```hcl
resource "google_compute_autoscaler" "workers" {
  name   = "spark-workers-autoscaler"
  target = google_compute_instance_group_manager.workers.self_link

  autoscaling_policy {
    min_replicas = 2
    max_replicas = 10
    cpu_utilization {
      target = 0.8
    }
  }
}
```

#### 4. Utiliser Cloud Storage au lieu de HDFS

```scala
// WordCount avec GCS
val input = "gs://my-bucket/input/data.txt"
val output = "gs://my-bucket/output/result"

spark.read.textFile(input)
  .flatMap(_.split("\\W+"))
  .groupBy("value")
  .count()
  .write.parquet(output)
```

### Haute disponibilitÃ©

#### NameNode HA avec Zookeeper

```yaml
# ansible/roles/hdfs/defaults/main.yml
hdfs_ha_enabled: true
namenode_ha_hosts:
  - master-1
  - master-2
zookeeper_hosts:
  - master-1:2181
  - master-2:2181
  - master-3:2181
```

#### Spark Master HA

```yaml
# ansible/roles/spark-master/defaults/main.yml
spark_ha_enabled: true
spark_master_recovery: ZOOKEEPER
spark_zookeeper_url: "master-1:2181,master-2:2181,master-3:2181"
```

### SÃ©curitÃ©

#### Activer Kerberos

```yaml
# ansible/roles/common/tasks/main.yml
- name: Configurer Kerberos
  apt:
    name:
      - krb5-user
      - krb5-config
    state: present
```

#### Chiffrer les communications

```yaml
# ansible/roles/spark-master/defaults/main.yml
spark_ssl_enabled: true
spark_ssl_keystore: /path/to/keystore.jks
spark_ssl_truststore: /path/to/truststore.jks
```

#### Authentification Spark

```yaml
spark_authentication_enabled: true
spark_secret: "{{ vault_spark_secret }}"
```

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues !

### Comment contribuer

1. **Fork** le projet
2. CrÃ©er une **branche** (`git checkout -b feature/AmazingFeature`)
3. **Commiter** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Pousser** vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une **Pull Request**

### Guidelines

- Suivre le style de code existant
- Ajouter des tests si applicable
- Mettre Ã  jour la documentation
- S'assurer que tous les tests passent

---

## ğŸ“š Ressources

### Documentation officielle

- [Apache Spark](https://spark.apache.org/docs/latest/)
- [Apache Hadoop](https://hadoop.apache.org/docs/stable/)
- [Terraform GCP Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)
- [Ansible Documentation](https://docs.ansible.com/)
- [Google Cloud Platform](https://cloud.google.com/docs)

### Tutoriels

- [Spark Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
- [HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Terraform Best Practices](https://www.terraform-best-practices.com/)

### CommunautÃ©

- [Stack Overflow - Apache Spark](https://stackoverflow.com/questions/tagged/apache-spark)
- [Spark User Mailing List](https://spark.apache.org/community.html)

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¨â€ğŸ’» Auteurs

- **Balekamen babatack landry** - *Travail initial* - [(https://github.com/Pharaminus)](https://github.com/Pharaminus)

---

## ğŸ™ Remerciements

- L'Ã©quipe Apache Spark pour ce framework incroyable
- La communautÃ© Terraform pour les modules GCP
- La communautÃ© Ansible pour les rÃ´les et playbooks

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :

1. Consulter la section [DÃ©pannage](#-dÃ©pannage)
2. VÃ©rifier les [Issues GitHub](https://github.com/votre-repo/issues)
3. Ouvrir une nouvelle issue si le problÃ¨me persiste

---

**Bon dÃ©ploiement ! ğŸš€**